# -*- coding: utf-8 -*-
"""Routes.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/14gi37Wl921rUKIDTFKDFh46PfCB-y8_R
"""

import requests
import json
import pandas as pd
from geopy.geocoders import Nominatim
from geopy.exc import GeocoderTimedOut
import math
import polyline
import folium

# Define the routes with start and end coordinates
routes = [
    {"start": {"lat": 33.7629, "lng": -84.4227}, "end": {"lat": 32.018, "lng": -81.1965}},
    {"start": {"lat": 32.018, "lng": -81.1965}, "end": {"lat": 33.3655, "lng": -82.0734}},
    {"start": {"lat": 33.3655, "lng": -82.0734}, "end": {"lat": 33.9496, "lng": -83.3701}},
    {"start": {"lat": 33.9496, "lng": -83.3701}, "end": {"lat": 32.8088, "lng": -83.6942}},
    {"start": {"lat": 32.8088, "lng": -83.6942}, "end": {"lat": 33.7629, "lng": -84.4227}},
]

# Your Google API Key (hidden for security)
api_key = *HIDDEN*

# Google Maps API endpoint
url = 'https://routes.googleapis.com/directions/v2:computeRoutes'

# List to store the route responses
route_objects = []

# Iterate over each route to request route details from Google Maps API
for route in routes:
    start_lat = route["start"]["lat"]
    start_lng = route["start"]["lng"]
    end_lat = route["end"]["lat"]
    end_lng = route["end"]["lng"]

    # Construct the payload for the API request
    payload = {
        "origin": {"location": {"latLng": {"latitude": start_lat, "longitude": start_lng}}},
        "destination": {"location": {"latLng": {"latitude": end_lat, "longitude": end_lng}}},
        "travelMode": "DRIVE",
        "routingPreference": "TRAFFIC_AWARE",
        "departureTime": "2024-05-17T19:00:00Z",
        "computeAlternativeRoutes": True,
        "routeModifiers": {
            "avoidTolls": False,
            "avoidHighways": False,
            "avoidFerries": False
        },
        "languageCode": "en-US",
        "units": "IMPERIAL"
    }

    # Set the request headers
    headers = {
        'Content-Type': 'application/json',
        'X-Goog-Api-Key': api_key,
        'X-Goog-FieldMask': 'routes.legs.steps.distanceMeters,routes.routeLabels,routes.legs.steps.startLocation.latLng,routes.legs.steps.endLocation.latLng,routes.polyline.encodedPolyline'
    }

    # Make the API request and handle potential errors
    try:
        response = requests.post(url, headers=headers, json=payload)
        response.raise_for_status()  # Raise exception for HTTP errors
        route_object = response.json()
        route_objects.append(route_object)
    except requests.exceptions.HTTPError as e:
        print(f"HTTP error occurred: {e}")
    except json.JSONDecodeError as e:
        print(f"JSON decoding error occurred: {e}")
    except Exception as e:
        print(f"An unexpected error occurred: {e}")

# Print the first route object for inspection
print(route_objects[0])

# Load the accident data in chunks for memory efficiency
chunk_size = 100000
filtered_chunks = []

for chunk in pd.read_csv("US_Accidents_March23.csv", chunksize=chunk_size):
    filtered_chunk = chunk[chunk['State'] == 'GA']
    filtered_chunks.append(filtered_chunk)

# Combine filtered chunks into a single DataFrame
df_ga = pd.concat(filtered_chunks, ignore_index=True)

# Extract the severity column and drop unnecessary columns
y = df_ga['Severity']
X = df_ga.iloc[:, 11:]
X.drop(columns=['State', 'Country', 'Timezone', 'Airport_Code'], inplace=True)
X['Severity'] = y

# Convert Weather_Timestamp to datetime and extract day of the week
X['Weather_Timestamp'] = pd.to_datetime(X['Weather_Timestamp'])
X['day_of_week'] = X['Weather_Timestamp'].dt.day_name()

# Function to check if a day is a weekday
def is_weekday(day):
    weekdays = ["Monday", "Tuesday", "Wednesday", "Thursday", "Friday"]
    return day in weekdays

# Create a Weekday column based on the day of the week
X['Weekday'] = X['day_of_week'].apply(lambda x: is_weekday(x))

# Drop unnecessary columns
X.drop(columns=['Weather_Timestamp', 'day_of_week'], inplace=True)

# Calculate the average severity for accidents in each city
df = X.groupby('City')['Severity'].mean().reset_index()

print(df)

# Initialize geolocator and define function to get latitude and longitude of a city
def get_lat_lon(city, retries=3):
    geolocator = Nominatim(user_agent="my_application")
    for _ in range(retries):
        try:
            location = geolocator.geocode(city, timeout=10)
            if location:
                return location.latitude, location.longitude
        except GeocoderTimedOut:
            continue
    return None, None

# Add Latitude and Longitude columns to the DataFrame
df['Latitude'] = 0.0
df['Longitude'] = 0.0

# Populate the Latitude and Longitude columns
for index, row in df.iterrows():
    city = row['City']
    latitude, longitude = get_lat_lon(city)
    df.at[index, 'Latitude'] = latitude
    df.at[index, 'Longitude'] = longitude

# Print the DataFrame to check the result
print(df)

# Print the row with the highest severity
print(df.loc[[df['Severity'].idxmax()]])

# Print the row with the lowest severity
print(df.loc[[df['Severity'].idxmin()]])

# Convert city data to a dictionary for easy lookup
city_data = df.set_index('City').to_dict(orient='index')

# List to store the results of danger calculations for each route
result_dicts = []

# Iterate through route objects to calculate cumulative danger
for route_obj in route_objects:
    result_dict = {}
    for route in route_obj['routes']:
        cumulative_danger = 0

        # Iterate through the legs of the route
        for leg in route['legs']:
            for step in leg['steps']:
                start_lat = step['startLocation']['latLng']['latitude']
                start_lon = step['startLocation']['latLng']['longitude']
                end_lat = step['endLocation']['latLng']['latitude']
                end_lon = step['endLocation']['latLng']['longitude']

                # Calculate the average location for the step
                avg_lat = (start_lat + end_lat) / 2
                avg_lon = (start_lon + end_lon) / 2

                # Find the corresponding city based on minimum distance
                min_distance = float('inf')
                corresponding_city = None
                for city, city_info in city_data.items():
                    city_lat = city_info['Latitude']
                    city_lon = city_info['Longitude']
                    distance = math.acos(math.sin(math.radians(avg_lat)) * math.sin(math.radians(city_lat)) + 
                                         math.cos(math.radians(avg_lat)) * math.cos(math.radians(city_lat)) * 
                                         math.cos(math.radians(city_lon - avg_lon)))

                    if distance < min_distance:
                        min_distance = distance
                        corresponding_city = city

                # Get the severity level for the corresponding city
                severity_level = df.loc[df['City'] == corresponding_city, 'Severity'].values[0]

                # Calculate the danger for the step
                danger = severity_level * step['distanceMeters']
                print(severity_level, corresponding_city, danger)

                # Add to cumulative danger for the route
                cumulative_danger += danger

        # Store the cumulative danger in the result dictionary
        result_dict[route['polyline']['encodedPolyline']] = cumulative_danger

    # Append the result dictionary to the result list
    result_dicts.append(result_dict)

# Print the result dictionaries for inspection
print(result_dicts)

# Extract and print the values and keys from the first result dictionary
print(result_dicts[0].values())
print(result_dicts[0].keys())

# Decode a polyline string and print the first few coordinates and total length
my_string = list(result_dicts[0].keys())[0]
l = polyline.decode(my_string)
print(l[:5])
print(len(l))

# Create a folium map and plot the polyline
latitudes, longitudes = zip(*l)
mean_latitude = sum(latitudes) / len(latitudes)
mean_longitude = sum(longitudes) / len(longitudes)

m = folium.Map(location=[mean_latitude, mean_longitude], zoom_start=8)
folium.PolyLine(locations=l, color="#FF0000", weight=5, tooltip="From Boston to San Francisco").add_to(m)

# Add all polylines to the map and highlight the best route
latitudes = []
longitudes = []
i = 0  # Index of the route to plot

for key in result_dicts[i].keys():
    l = polyline.decode(key)
    latitudes_temp, longitudes_temp = zip(*l)
    latitudes.extend(latitudes_temp)
    longitudes.extend(longitudes_temp)

mean_latitude = sum(latitudes) / len(latitudes)
mean_longitude = sum(longitudes) / len(longitudes)
best_key = min(result_dicts[i], key=result_dicts[i].get)

# Create the map and add the lines
m = folium.Map(location=[mean_latitude, mean_longitude], zoom_start=8)

for key in result_dicts[i].keys():
    if key != best_key:
        l = polyline.decode(key)
        folium.PolyLine(locations=l, color="#FF0000", weight=5, tooltip="Alternative Route").add_to(m)

l = polyline.decode(best_key)
folium.PolyLine(locations=l, color="#0000FF", weight=5, tooltip="Best Route").add_to(m)

# Add a legend to the map
legend_html = '''
     <div style="position: fixed;
                 bottom: 50px; left: 50px; width: 180px; height: 90px;
                 border:2px solid grey; z-index:9999; font-size:14px;
                 background-color:white;
                 ">&nbsp; <b>Legend</b> <br>
                   &nbsp; Best Route &nbsp; <i class="fa fa-map-marker fa-2x" style="color:blue"></i><br>
                   &nbsp; Alternative Route &nbsp; <i class="fa fa-map-marker fa-2x" style="color:red"></i>
     </div>
     '''
m.get_root().html.add_child(folium.Element(legend_html))

# Display the map
m
